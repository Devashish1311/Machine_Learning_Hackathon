# Machine_Learning_Hackathon
During my working on the project related to data analysis for the Machine Learning club.I got to know a lot of things.
It started with a struggle to install the numpy and pandas which i realised later were difficult to install as i didn't have pip installed in my system.
Coming to the problem statement I took help from internet on how to import the data file into the VS code using pandas, which was followed by installing a few moew libraries and thus importing modules.
Then as I didn't know how to code I took help of chatgpt(for the complete code and plots) and with it's help found the code for visualizing the missing values as a heatmap.
This was followed by the code for visualising the distribution of frequency of movies with respect to the release years which highlighted the monumental increase in movie production.
This was followed by distributing the content in form of movies and TV shows, which shows movies are produced in huge numbers in comparison to TV shows.
After this I used one hot encoding for the type and rating cateogaries, which basically separates on the basis of 0s and 1s.
Before that I even had filled empty values by 'unknown'. And converted all column enteries to strings regardless of the data values entered in them.
This was followed by extraction of data from duration columns containing numerical values with'min' and 'seasons'. The code took up just the numeric part from them using lambda function.
After this I plotted the graph for the durartion of movies and release years as a scatter plot which made me realize the varying trend in the data.
Then the same graph concept was used but plotted for TV shows which showed a more uniform trend.
I also created a data line analysing the trend for release year which told when the first movie was released, followed by the time when 25, 50 , 75 % of the movies and TV shows were released. Also the year which had maximum releases was also found.
This was followed by creating a code for the predicted and actual duration for both movies and TV shows on one plot, wherein one season was treated as 60 minutes on average for the purpose of simplification. And expected duration was predicteed by using some defined values. And thus the data was plotted, this was followed by generation of a regression line. After exploring about it found it gives an estimate plot between the X and Y axis variables. And the shaded area that comes is due to the confidence parameter that is the precision with which the regression line represents the relationship between the X and Y plots. The area represents the uncertainity in the region wherein the values of X and Y may lie. Also where the data density is high the area tends to be minimum as the precision decreases while where the data is scarce the area expanded. This was due to the reason as due to less data values the precision is also less.
This was also followed by printing the data about how many movies and TV shows were released in particular years.
Also all the durations were finally converted into minutes(considering 1 season = 60 minutes)
Thus I finished the project along with answering a few questions which were based on the genre and the movie and show trends also some like the duration and year of release,also there were comparative trends between movies and TV shows on the same basis of number of releases.I have tried my best to understand the code provided by chatgpt and also the large number of errors which frustated me,(particularly one where I had by mistake defined another data set and thus the problem forcommon column arose.) It was quite tiring but indeed a fun experience as well.
